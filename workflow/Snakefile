# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,


# load configuration
# -----------------------------------------------------
configfile: "config/config.yaml"


# load rules
# -----------------------------------------------------
include: "rules/common.smk"



# optional messages, log and error handling
# -----------------------------------------------------
onstart:
    print("\n--- Welcome! ---\n")
    print("\n--- This is pure-faf! - Purification through formalin artefact filtering ---\n")


onsuccess:
    print("\n--- pure-faf finished! ---\n")


onerror:
    print("\n--- What a faf! An error occurred! ---\n")

# wildcard constraints
# -----------------------------------------------------
WILDCARD_CONSTRAINTS = {
    "tum": "|".join(samples["tumour_name"])
}
wildcard_constraints:
    tum=WILDCARD_CONSTRAINTS["tum"]


# target rules
# -----------------------------------------------------
rule all:
    input:
        f"{ODIR}/ffpe_sig/cosine_similarity_repaired_ffpe_sig.tsv",
        f"{ODIR}/ffpe_sig/cosine_similarity_unrepaired_ffpe_sig.tsv",
        f"{ODIR}/ffpe_sig/cosine_similarity_plot_repaired.pdf",
        f"{ODIR}/ffpe_sig/cosine_similarity_plot_unrepaired.pdf"
    default_target: True


# Reorder Mutect2 vcf to have normal sample first, tumour sample secod
# because some of the later steps depend on this order
# -----------------------------------------------------
rule reorder_Mutect2_vcf:
    input:get_mutect2_vcf
    output:
        temp(f"{ODIR}/temp/1-reordered_{{tum}}.vcf.gz"),
        temp(f"{ODIR}/temp/1-reordered_{{tum}}.vcf.gz.csi")
    conda:
        "envs/bcftools.yaml"
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    threads:1
    params:
        normal_name=get_normal_name
    log:
        f"{ODIR}/logs/1-reorder_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&
        bcftools view -s {params.normal_name},{wildcards.tum} --write-index -Oz -o {output[0]} {input} >> {log} 2>&1
        """

# Normalize vcf, fix a bug in vcf tag, and index the vcf
# This is to ensure every line in the vcf has only one alt allele
# -----------------------------------------------------
rule vcf_normalise:
    input:
        f"{ODIR}/temp/1-reordered_{{tum}}.vcf.gz.csi",
        v=f"{ODIR}/temp/1-reordered_{{tum}}.vcf.gz"
    output:
        v_temp=temp(f"{ODIR}/temp/2-norm_{{tum}}.vcf"),
        v=temp(f'{ODIR}/temp/2-norm_{{tum}}.vcf.gz'),
        i=temp(f'{ODIR}/temp/2-norm_{{tum}}.vcf.gz.csi')
    conda:
        "envs/bcftools.yaml"
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    threads:1 
    log:
        f"{ODIR}/logs/2-vcf_normalise_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&
        bcftools norm -m -any {input.v} 2> {log} \
        | sed 's/##INFO=<ID=AS_FilterStatus,Number=A/##INFO=<ID=AS_FilterStatus,Number=1/' \
        > {output.v_temp} 2>> {log} &&
        bcftools view --write-index -Oz -o {output.v} {output.v_temp} >> {log} 2>&1
        """

# Annotate VCF files with BETA shape parameters from FFPE PON
# -----------------------------------------------------
rule pon_annotate:
    """
    Annotate vcf with FFPE PON
    """
    input:
        v=f'{ODIR}/temp/2-norm_{{tum}}.vcf.gz',
        i=f'{ODIR}/temp/2-norm_{{tum}}.vcf.gz.csi',
        header= "resources/header.hdr",
        pon=get_PON
    output:
        v=f"{ODIR}/PON/1-{{tum}}_PON_annotated.vcf.gz",
        i=f"{ODIR}/PON/1-{{tum}}_PON_annotated.vcf.gz.csi"
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    threads:1 
    conda:
        "envs/bcftools.yaml"
    log:
        f"{ODIR}/logs/3-pon_annotate_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&
        bcftools annotate \
            --write-index \
            -a {input.pon} \
            -c CHROM,FROM,TO,INFO/BETA,INFO/FRACTION \
            -h {input.header} \
            {input.v} -Oz -o {output.v} >> {log} 2>&1
        """

# test whether the allelic frequency of the alternate allele in the VCF fits
# the distribution of the allelic frequencies in the PON
# SAMPLE ORDER MATTERS
# normal first, tumour second.
# -----------------------------------------------------
rule test_beta_dist: 
    input:
        v=f"{ODIR}/PON/1-{{tum}}_PON_annotated.vcf.gz",
        i=f"{ODIR}/PON/1-{{tum}}_PON_annotated.vcf.gz.csi"
    output:
        temp_v=temp(f"{ODIR}/PON/2-{{tum}}_beta_dist_tested.vcf"),
        v=f"{ODIR}/PON/2-{{tum}}_beta_dist_tested.vcf.gz",
        i=f"{ODIR}/PON/2-{{tum}}_beta_dist_tested.vcf.gz.csi"
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    threads:1 
    conda:
        "envs/test_beta.yaml"
    log:
        f"{ODIR}/logs/4-beta_dist_test_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&
        python workflow/scripts/test_pon_betadist_from_normal_first_tumour_second_vcf.py {input.v} {output.temp_v} >> {log} 2>&1 && \
        bcftools view  --write-index -Oz -o {output.v} {output.temp_v} >> {log} 2>&1
        """
# Filter vcf based on quality metrics
#Â Variants are kept if 
#AD> <threshold> & ROQ>= <threshold> & DP> <threshold> & FILTER is PASS or clustered_events or on panel_of_normals & p_ADfit < <threshold>
# -----------------------------------------------------
rule qual_filter:
    input:
        f'{ODIR}/PON/2-{{tum}}_beta_dist_tested.vcf.gz.csi',
        v=f'{ODIR}/PON/2-{{tum}}_beta_dist_tested.vcf.gz'
    output:
        v=f'{ODIR}/PON/3-filtered_{{tum}}.vcf.gz',
        i=f'{ODIR}/PON/3-filtered_{{tum}}.vcf.gz.csi'
    params:
        AD=AD,
        ROQ=ROQ,
        PON_ALPHA=PON_ALPHA,
        DP=DP
    conda:
        "envs/bcftools.yaml"
    threads: 1
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    log:
        f"{ODIR}/logs/5-quality_filter_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&
        bcftools view --write-index \
        -i '(FORMAT/DP[1]>{params.DP} && INFO/ROQ>={params.ROQ} && FMT/AD[1:1]>{params.AD}) && (INFO/p_ADfit < {params.PON_ALPHA} || INFO/p_ADfit = ".") && (FILTER="PASS" || FILTER="clustered_events" || FILTER="panel_of_normals" || FILTER="clustered_events;panel_of_normals" || FILTER="panel_of_normals;clustered_events")' \
        -Oz -o {output.v} {input.v} >> {log} 2>&1
        """

# Split vcf into snvs and indels and tiers based on AD threshold
# -----------------------------------------------------
rule split_snv_indel:
    input:
        f'{ODIR}/PON/3-filtered_{{tum}}.vcf.gz.csi',
        v=f'{ODIR}/PON/3-filtered_{{tum}}.vcf.gz'
    output:
        s=f'{ODIR}/temp/3-snv_high_AD_{{tum}}.vcf.gz',
        i1=f'{ODIR}/temp/3-snv_high_AD_{{tum}}.vcf.gz.csi',
        s_low_AD=f'{ODIR}/temp/3-snv_low_AD_{{tum}}.vcf.gz',
        i0 =f'{ODIR}/temp/3-snv_low_AD_{{tum}}.vcf.gz.csi',
        ind=f'{ODIR}/temp/4-indel_high_AD_{{tum}}.vcf.gz',
        i2=f'{ODIR}/temp/4-indel_high_AD_{{tum}}.vcf.gz.csi',
        ind_low_AD=f'{ODIR}/temp/4-indel_low_AD_{{tum}}.vcf.gz',
        i3=f'{ODIR}/temp/4-indel_low_AD_{{tum}}.vcf.gz.csi'
    params:
        AD_TIER=AD_TIER
    conda:
        "envs/bcftools.yaml"
    threads: 1
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    log:
        f"{ODIR}/logs/6-split_snv_indel_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&
        bcftools view --write-index -v snps -i 'FMT/AD[1:1]>={params.AD_TIER}' -Oz -o {output.s} {input.v} >> {log} 2>&1 && 
        bcftools view --write-index -v snps -i 'FMT/AD[1:1]<{params.AD_TIER}' -Oz -o {output.s_low_AD} {input.v} >> {log} 2>&1 && 
        bcftools view --write-index -v indels -i 'FMT/AD[1:1]>={params.AD_TIER}' -Oz -o {output.ind} {input.v} >> {log} 2>&1 && 
        bcftools view --write-index -v indels -i 'FMT/AD[1:1]<{params.AD_TIER}' -Oz -o {output.ind_low_AD} {input.v} >> {log} 2>&1
        """
# Intersect low-AD indels with Strelka2 indels
# Position-based intersection, requiring same type of mut (INS/DEL), no alt allele enforcement
# -----------------------------------------------------
rule indel_low_AD_strelka_intersection:
    input:
        ind_low_AD = f"{ODIR}/temp/4-indel_low_AD_{{tum}}.vcf.gz",
        i3         = f"{ODIR}/temp/4-indel_low_AD_{{tum}}.vcf.gz.csi",
        strelka_indel = get_strelka_vcf,
        ref = REF_GEN
    output:
        ind_low_AD_strelka = f"{ODIR}/temp/5-indel_low_AD_strelka_intersected_{{tum}}.vcf.gz",
        i4                  = f"{ODIR}/temp/5-indel_low_AD_strelka_intersected_{{tum}}.vcf.gz.csi",
        # intermediates
        m2_norm             = temp(f"{ODIR}/temp/5-indel_low_AD_{{tum}}.norm.vcf.gz"),
        m2_norm_csi         = temp(f"{ODIR}/temp/5-indel_low_AD_{{tum}}.norm.vcf.gz.csi"),
        st_norm             = temp(f"{ODIR}/temp/5-strelka_{{tum}}.norm.vcf.gz"),
        st_norm_csi         = temp(f"{ODIR}/temp/5-strelka_{{tum}}.norm.vcf.gz.csi"),
        m2_bed_uns          = temp(f"{ODIR}/temp/5-indel_low_AD_{{tum}}.unsorted.bed"),
        st_bed_uns          = temp(f"{ODIR}/temp/5-strelka_{{tum}}.unsorted.bed"),
        m2_bed              = temp(f"{ODIR}/temp/5-indel_low_AD_{{tum}}.bed"),
        st_bed              = temp(f"{ODIR}/temp/5-strelka_{{tum}}.bed"),
        match_bed           = f"{ODIR}/temp/5-indel_low_AD_strelka_{{tum}}.match.bed"
    conda:
        "envs/bcftools.yaml"
    threads: 8
    resources:
        mem_mb=16000,
        slurm_cpus_per_task=8
    log:
        f"{ODIR}/logs/7-indel_low_AD_strelka_intersect_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&

        set -euo pipefail 
        export LC_ALL=C 

        # Ensure reference index exists
        [ -s {input.ref}.fai ] || samtools faidx {input.ref} >> {log} 2>&1 &&

        # 1) Normalize & split multiallelics (write index inline) with threads
        bcftools norm --threads {threads} -f {input.ref} -m -any --write-index -Oz -o {output.m2_norm} {input.ind_low_AD} >> {log} 2>&1 &&
        bcftools norm --threads {threads} -f {input.ref} -m -any --write-index -Oz -o {output.st_norm} {input.strelka_indel} >> {log} 2>&1 &&

        # 2) Extract INDELs to BED (VCF 1-based -> BED 0-based)
        bcftools query -i 'TYPE="indel"' -f '%CHROM\\t%POS\\t%REF\\t%ALT\\n' {output.m2_norm} \
        | awk 'BEGIN{{OFS="\\t"}}{{
            lr=length($3); la=length($4);
            if(la>lr)      print $1, $2-1, $2, "INS";
            else if(lr>la) print $1, $2-1, $2-1+(lr-la), "DEL";
        }}' > {output.m2_bed_uns} 2>> {log} &&

        bcftools query -i 'TYPE="indel"' -f '%CHROM\\t%POS\\t%REF\\t%ALT\\n' {output.st_norm} \
        | awk 'BEGIN{{OFS="\\t"}}{{
            lr=length($3); la=length($4);
            if(la>lr)      print $1, $2-1, $2, "INS";
            else if(lr>la) print $1, $2-1, $2-1+(lr-la), "DEL";
        }}' > {output.st_bed_uns} 2>> {log} &&

        # 2b) Sort BEDs once (numeric), then use bedtools -sorted
        sort --parallel={threads} -S {resources.mem_mb}M -k1,1 -k2,2n {output.m2_bed_uns} > {output.m2_bed} 2>> {log} && 
        sort --parallel={threads} -S {resources.mem_mb}M -k1,1 -k2,2n {output.st_bed_uns} > {output.st_bed} 2>> {log} &&

        # 3) Intersect and require SAME TYPE ONLY (faster with -sorted)
        bedtools intersect -sorted -a {output.m2_bed} -b {output.st_bed} -wa -wb \
        | awk 'BEGIN{{OFS="\\t"}} {{ if($4==$8) print $1,$2,$3 }}' \
        | sort --parallel={threads} -S {resources.mem_mb}M -k1,1 -k2,2n -u > {output.match_bed} 2>> {log} &&

        # 4) Subset Mutect2 to matched regions
        if [ -s {output.match_bed} ]; then
          bcftools view --threads {threads} -R {output.match_bed} --write-index -Oz -o {output.ind_low_AD_strelka} {output.m2_norm}
        else
          bcftools view --threads {threads} -h --write-index -Oz -o {output.ind_low_AD_strelka} {output.m2_norm}
        fi >> {log} 2>&1
        """

#  Merge high-AD SNVs and INDELs.
# -----------------------------------------------------
rule merge_high_AD:
    input:
        s=f'{ODIR}/temp/3-snv_high_AD_{{tum}}.vcf.gz',
        i1=f'{ODIR}/temp/3-snv_high_AD_{{tum}}.vcf.gz.csi',
        ind=f'{ODIR}/temp/4-indel_high_AD_{{tum}}.vcf.gz',
        i2=f'{ODIR}/temp/4-indel_high_AD_{{tum}}.vcf.gz.csi'
    output:
        v=f'{ODIR}/temp/6-high_AD_variants_{{tum}}.vcf.gz',
        i=f'{ODIR}/temp/6-high_AD_variants_{{tum}}.vcf.gz.csi'
    conda:
        "envs/bcftools.yaml"
    threads: 1
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    log:
        f"{ODIR}/logs/8-merge_high_AD_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&
        bcftools concat  --write-index --allow-overlaps --rm-dups none -Oz -o {output.v} {input.s} {input.ind} >> {log} 2>&1
        """

#  Merge low-AD SNVs and strelaka- intersected INDELs.
# -----------------------------------------------------
use rule merge_high_AD as merge_low_AD with:
    input:
        s=f'{ODIR}/temp/3-snv_low_AD_{{tum}}.vcf.gz',
        i1=f'{ODIR}/temp/3-snv_low_AD_{{tum}}.vcf.gz.csi',
        ind=f'{ODIR}/temp/5-indel_low_AD_strelka_intersected_{{tum}}.vcf.gz',
        i2=f'{ODIR}/temp/5-indel_low_AD_strelka_intersected_{{tum}}.vcf.gz.csi'
    output:
        v=f'{ODIR}/temp/6-low_AD_variants_{{tum}}.vcf.gz',
        i=f'{ODIR}/temp/6-low_AD_variants_{{tum}}.vcf.gz.csi'
    log:
        f"{ODIR}/logs/9-merge_low_AD_{{tum}}.log"


# Create mutation information file for Microsec 
# -----------------------------------------------------
rule mutation_information_file:
    input:
        v=f'{ODIR}/temp/6-{{AD_tier}}_variants_{{tum}}.vcf.gz',
        i=f'{ODIR}/temp/6-{{AD_tier}}_variants_{{tum}}.vcf.gz.csi'
    output:
        f"{ODIR}/microsec_input/mutation_info_{{AD_tier}}_variants_{{tum}}.txt"
    conda:
        "envs/bcftools.yaml"
    threads: 1
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    params:
        chr=get_chr
    log:
        f"{ODIR}/logs/10-mutation_info_{{AD_tier}}_variants_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&

        if [ "{params.chr}" == "chr" ]; then
            CHR="chr"
        else
            CHR=""
        fi >> {log} 2>&1 &&
        
        echo -e "Sample\\tMut_type\\tChr\\tPos\\tRef\\tAlt\\tSimpleRepeat_TRF\\tNeighborhood_sequence\\tpercent_Alt\\tsum_AD" > {output} 2>> {log} && 

        bcftools query -s {wildcards.tum} -r "$(echo ${{CHR}}{{1..22}} ${{CHR}}X ${{CHR}}Y | tr ' ' ',')" \
        -f '%CHROM\\t%POS\\t%REF\\t%ALT\\t[%AD{{0}}\\t%AD{{1}}]\\n' {input.v} \
        | awk -v samp={wildcards.tum} '{{
        chr=$1; pos=$2; ref=$3; alt=$4; ad_r=$5; ad_a=$6;
        mut="-"; percent_alt=ad_a/(ad_r+ad_a)*100; sum_ad=ad_r+ad_a;
        print samp "\\t" mut "\\t" chr "\\t" pos "\\t" ref "\\t" alt "\\t-\\t-" "\\t" percent_alt "\\t" sum_ad
        }}' >> {output} 2>> {log}
        """

# Create sample information TSV for MicroSEC (File 3) with all 10 columns.
#    Columns:
#      [sample] [mutation_tsv] [bam] [readlen] [adapter1] [adapter2] [hg tag] [panel] [ref.fa] [simpleRepeat.bed(.gz)] 
# -----------------------------------------------------
rule sample_information_file:
    input:
        mif = f"{ODIR}/microsec_input/mutation_info_{{AD_tier}}_variants_{{tum}}.txt",
        bam = get_tumour_bam,        
        ref = REF_GEN,
        simple_repeat = get_SR
    output:
        f"{ODIR}/microsec_input/sample_info_{{AD_tier}}_variants_{{tum}}.txt"
    params:
        read_length = get_sequencing_read_length,
        adapter1 = get_sequencing_adapter_1,
        adapter2 = get_sequencing_adapter_2,
        genome = "hg38" if str(config["ref_genome_version"]).lower()=="grch38" else "hg19"
    threads: 1
    resources:
        mem_mb = 5000,
        slurm_cpus_per_task=1
    log:
        f"{ODIR}/logs/11-sample_info_{{AD_tier}}_variants_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&

        printf "%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n" \
            {wildcards.tum} \
            $(realpath {input.mif}) \
            {input.bam} \
            {params.read_length} \
            {params.adapter1} \
            {params.adapter2} \
            {params.genome} \
            custom_panel \
            {input.ref} \
            {input.simple_repeat} \
            > {output} 2>> {log}
        """

# intall BSgenome.Hsapiens.UCSC.hg19 because it's not included in the microsec singularity image
# won't be run if reference genome is GRCh38
# ------------------------------------------------------------------------------
rule install_bsgenome_hg19:    
    output: 
        directory(".Rlib/BSgenome.Hsapiens.UCSC.hg19"),
        ".Rlib/hg19_download_complete.txt"
    container:
        "docker://ikegamitky/microsec:v2.1.6"
    threads: 2
    resources:
        mem_mb=8000,
        slurm_cpus_per_task=4
    log:
        f"{ODIR}/logs/12.0_install_bsgenome_hg19.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&

        mkdir -p .Rlib
        Rscript --vanilla -e '
        .libPaths(".Rlib")
        if (!requireNamespace("BSgenome.Hsapiens.UCSC.hg19", quietly = TRUE)) {{
        BiocManager::install("BSgenome.Hsapiens.UCSC.hg19",ask = FALSE, update = FALSE, lib = ".Rlib")
        }}' >> {log} 2>&1 &&
        echo "h19_download_complete" | tee .Rlib/hg19_download_complete.txt >> {log} 2>&1
        """

# run microsec for high AD variants
# -----------------------------------------------------
rule microsec_high_AD:
    input:
        bsgenome=bsgenome_prereq(),
        sample_info=f"{ODIR}/microsec_input/sample_info_high_AD_variants_{{tum}}.txt",
        mutation_info=f"{ODIR}/microsec_input/mutation_info_high_AD_variants_{{tum}}.txt"
    output:
        msec=f"{ODIR}/microsec_output/{{tum}}_high_AD.tsv.gz",
        slim_bam  = temp(f"{ODIR}/microsec_output/tmp/{{tum}}_high_AD/{{tum}}.SLIM.bam"),
        slim_bai  = temp(f"{ODIR}/microsec_output/tmp/{{tum}}_high_AD/{{tum}}.SLIM.bam.bai"),
        regions   = temp(f"{ODIR}/microsec_output/tmp/{{tum}}_high_AD/{{tum}}.regions.bed")
    container:
        "docker://ikegamitky/microsec:v2.1.6"
    threads: 4
    resources:
        mem_mb=20000,
        slurm_cpus_per_task=4
    params:
        threshold_p=config["pval_threshold_high_AD"],
        mem_per_thread=lambda wildcards, threads, resources: int(resources.mem_mb / threads)
    log:
        f"{ODIR}/logs/12-microsec_high_AD_{{tum}}.log"
    script:
        "scripts/MicroSEC_parameterised2.R"

# run microsec for high AD variants
# -----------------------------------------------------
rule microsec_low_AD:
    input:
        bsgenome=bsgenome_prereq(),
        sample_info=f"{ODIR}/microsec_input/sample_info_low_AD_variants_{{tum}}.txt",
        mutation_info=f"{ODIR}/microsec_input/mutation_info_low_AD_variants_{{tum}}.txt"
    output:
        msec=f"{ODIR}/microsec_output/{{tum}}_low_AD.tsv.gz",
        slim_bam  = temp(f"{ODIR}/microsec_output/tmp/{{tum}}_low_AD/{{tum}}.SLIM.bam"),
        slim_bai  = temp(f"{ODIR}/microsec_output/tmp/{{tum}}_low_AD/{{tum}}.SLIM.bam.bai"),
        regions   = temp(f"{ODIR}/microsec_output/tmp/{{tum}}_low_AD/{{tum}}.regions.bed")
    container:
        "docker://ikegamitky/microsec:v2.1.6"
    threads: 4
    resources:
        mem_mb=20000,
        slurm_cpus_per_task=4
    params:
        threshold_p=config["pval_threshold_low_AD"],
        mem_per_thread=lambda wildcards, threads, resources: int(resources.mem_mb / threads)
    log:
        f"{ODIR}/logs/13-microsec_low_AD_{{tum}}.log"
    script:
        "scripts/MicroSEC_parameterised2.R"

#  Annotate Mutect2 filtered VCF with Microsec results
# -----------------------------------------------------
rule microsec_annotate:
    input:
        v=f'{ODIR}/temp/6-{{AD_tier}}_variants_{{tum}}.vcf.gz',
        i=f'{ODIR}/temp/6-{{AD_tier}}_variants_{{tum}}.vcf.gz.csi',
        microsec=f"{ODIR}/microsec_output/{{tum}}_{{AD_tier}}.tsv.gz",
        header="resources/microsec_vcf_header.hdr"
    output:
        tbi= temp(f"{ODIR}/microsec_output/{{tum}}_{{AD_tier}}_modified_header.tsv.gz.tbi"),
        microsec_output_1=temp(f"{ODIR}/microsec_output/{{tum}}_{{AD_tier}}_modified_header.tsv"),
        microsec_output_2=temp(f"{ODIR}/microsec_output/{{tum}}_{{AD_tier}}_modified_header.tsv.gz"),
        v=temp(f"{ODIR}/temp/7-{{AD_tier}}_variants_{{tum}}_msec_annotated.vcf.gz"),
        i=temp(f"{ODIR}/temp/7-{{AD_tier}}_variants_{{tum}}_msec_annotated.vcf.gz.csi")
    threads: 2
    resources:
        mem_mb=10000,
        slurm_cpus_per_task=2
    conda:
        "envs/bcftools.yaml"
    log:
        f"{ODIR}/logs/14-microsec_annotate_{{AD_tier}}_variants_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&

        #0 ) check microsec output column names
        expected_header=$'Sample\tMut_type\tChr\tPos\tRef\tAlt\tSimpleRepeat_TRF\tNeighborhood_sequence\tpercent_Alt\tsum_AD\tChr_original\tChr_bam\tread_length\ttotal_read\tsoft_clipped_read\tflag_hairpin\tpre_support_length\tpost_support_length\tshort_support_length\tpre_farthest\tpost_farthest\tlow_quality_base_rate_under_q18\tlow_quality_pre\tlow_quality_post\tdistant_homology_rate\tsoft_clipped_rate\tprob_filter_1\tprob_filter_3_pre\tprob_filter_3_post\tfilter_1_mutation_intra_hairpin_loop\tfilter_2_hairpin_structure\tfilter_3_microhomology_induced_mutation\tfilter_4_highly_homologous_region\tfilter_5_soft_clipped_reads\tfilter_6_simple_repeat\tfilter_7_mutation_at_homopolymer\tfilter_8_low_quality\tmsec_filter_123\tmsec_filter_1234\tmsec_filter_all\tcomment'
        echo "expected_header: $expected_header" >> {log} 2>&1

        actual_header=$(zcat {input.microsec} | sed -n '1p')

        if [ "$actual_header" != "$expected_header" ]; then
            echo "[microsec_annotate] ERROR: MicroSEC TSV header mismatch!" >> {log} 2>&1
            echo "[microsec_annotate] Expected header:" >> {log} 2>&1
            echo "[microsec_annotate]   $expected_header" >> {log} 2>&1
            echo "[microsec_annotate] Got header:" >> {log} 2>&1
            echo "[microsec_annotate]   $actual_header" >> {log} 2>&1
            exit 1
        fi

        # 1) Empty split VCF -> passthrough (already empty)
        if [ "$(bcftools view -H {input.v} | head -n1 | wc -l)" -eq 0 ]; then
            echo "[microsec_annotate] Split VCF is empty; passing through unchanged." >> {log} 2>&1

            : > {output.microsec_output_1}
            bgzip -c {output.microsec_output_1} > {output.microsec_output_2} 2>> {log} || true
            touch {output.tbi}

            cp {input.v} {output.v}
            cp {input.i} {output.i}
            exit 0
        fi

        # 2) MicroSEC empty but split VCF non-empty -> header-only VCF
        if [ "$(zcat {input.microsec} | wc -l)" -eq 0 ]; then
            echo "[microsec_annotate] MicroSEC result empty; emitting empty VCF." >> {log} 2>&1

            : > {output.microsec_output_1}
            bgzip -c {output.microsec_output_1} > {output.microsec_output_2} 2>> {log} || true
            touch {output.tbi}

            bcftools view -h {input.v} \
              | bgzip -c > {output.v} 2>> {log}

            bcftools index -f {output.v} >> {log} 2>&1
            exit 0
        fi

        # 3) Normal path: annotate
        echo "[microsec_annotate] Annotating VCF using MicroSEC output." >> {log} 2>&1

        zcat {input.microsec} | sed 's/^Sample/#Sample/' > {output.microsec_output_1} 2>> {log} &&
        bgzip -c {output.microsec_output_1} > {output.microsec_output_2} 2>> {log} &&
        tabix -f -s3 -b4 -e4 {output.microsec_output_2} >> {log} 2>&1 &&
        bcftools annotate \
            --write-index --threads {threads} \
            -a {output.microsec_output_2} \
            -c -,-,CHROM,POS,REF,ALT,-,-,-,msec_alt_AD,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,filter_1_mutation_intra_hairpin_loop,filter_2_hairpin_structure,filter_3_microhomology_induced_mutation,filter_4_highly_homologous_region,filter_5_soft_clipped_reads,filter_6_simple_repeat,filter_7_mutation_at_homopolymer,filter_8_low_quality,msec_filter_123,msec_filter_1234,msec_filter_all,comment \
            -h {input.header} \
            {input.v} -Oz -o {output.v} >> {log} 2>&1
        """

#     Merge high and low AD Microsec annotated VCFs
# -----------------------------------------------------        
rule AD_tiers_merge:
    input:
        high_v=f'{ODIR}/temp/7-high_AD_variants_{{tum}}_msec_annotated.vcf.gz',
        high_i=f'{ODIR}/temp/7-high_AD_variants_{{tum}}_msec_annotated.vcf.gz.csi',
        low_v=f'{ODIR}/temp/7-low_AD_variants_{{tum}}_msec_annotated.vcf.gz',
        low_i=f'{ODIR}/temp/7-low_AD_variants_{{tum}}_msec_annotated.vcf.gz.csi'
    output:
        v=temp(f'{ODIR}/temp/8-{{tum}}_msec_annotated.vcf.gz'),
        i=temp(f'{ODIR}/temp/8-{{tum}}_msec_annotated.vcf.gz.csi')
    threads: 1
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    conda:
        "envs/bcftools.yaml"
    log:
        f"{ODIR}/logs/15-AD_tiers_merge_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&
        
        bcftools concat  --write-index --allow-overlaps --rm-dups none -Oz -o {output.v} {input.high_v} {input.low_v} >> {log} 2>&1
        """

#  Download VEP cache
# -----------------------------------------------------

rule download_VEP_cache:
    output:
        directory(".vep_cache/homo_sapiens"),
        ".vep_cache/download_complete_GRCh38.txt" if str(config["ref_genome_version"]).lower()=="grch38" else ".vep_cache/download_complete_GRCh37.txt"
    threads: 1
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    container:
        "docker://ensemblorg/ensembl-vep"
    log:
        f"{ODIR}/logs/16-download_VEP_cache.log"
    params:
        ref_gen=str(config["ref_genome_version"]).lower()
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&

        #create cache directory if doesn't exist
        if [ ! -d ".vep_cache" ]; then
            mkdir -p .vep_cache >> {log} 2>&1
        fi
        if [ "{params.ref_gen}" = "grch38" ]; then
            INSTALL.pl -c .vep_cache -a cf -s homo_sapiens -y GRCh38 >> {log} 2>&1
            echo "Download complete GRCh38" | tee .vep_cache/download_complete_GRCh38.txt >> {log} 2>&1
        else
            INSTALL.pl -c .vep_cache -a cf -s homo_sapiens -y GRCh37 >> {log} 2>&1
            echo "Download complete GRCh37" | tee .vep_cache/download_complete_GRCh37.txt >> {log} 2>&1
        fi         
        """

# Annotate VCF with VEP
# -----------------------------------------------------
rule VEP_annotate:
    input:
        ".vep_cache/download_complete_GRCh38.txt" if str(config["ref_genome_version"]).lower()=="grch38" else ".vep_cache/download_complete_GRCh37.txt",
        f'{ODIR}/temp/8-{{tum}}_msec_annotated.vcf.gz.csi',
        v=f'{ODIR}/temp/8-{{tum}}_msec_annotated.vcf.gz'
    output:
        v=f'{ODIR}/temp/9-{{tum}}_msec_vep_annotated.vcf.gz'
    threads: 4
    resources:
        mem_mb=20000,
        slurm_cpus_per_task=4
    container:
        "docker://ensemblorg/ensembl-vep"
    params:
        ncbi="GRCh38" if str(config["ref_genome_version"]).lower()=="grch38" else "GRCh37"
    log:
        f"{ODIR}/logs/17-VEP_annotate_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&
        zcat {input.v} | vep \
        --input_file STDIN \
        --format vcf \
        -o {output.v} \
        --symbol --everything \
        --assembly {params.ncbi} \
        --offline --cache \
        --dir_cache .vep_cache \
        --no_stats \
        --filter_common \
        --per_gene \
        --total_length \
        --fork {threads} \
        --vcf \
        --compress_output bgzip >> {log} 2>&1
        """

# filter VCF file based on Microsec annotations
# -----------------------------------------------------
rule msec_filter:
    """
    Apply Microsec filters to the annotated VCF
    """
    input:
        v=f'{ODIR}/temp/9-{{tum}}_msec_vep_annotated.vcf.gz'
    output:
        temp(f'{ODIR}/temp/9-{{tum}}_msec_vep_annotated.vcf.gz.csi'),
        temp(f'{ODIR}/filtered_vcf/{{tum}}_vault_filtered_novaf.vcf.gz.csi'),
        temp(f'{ODIR}/filtered_vcf/{{tum}}_vault_plus_SR_filtered_novaf.vcf.gz.csi'),
        temp(f'{ODIR}/filtered_vcf/{{tum}}_msec_all_filtered_novaf.vcf.gz.csi'),
        v1=temp(f'{ODIR}/filtered_vcf/{{tum}}_vault_filtered_novaf.vcf.gz'),
        v2=temp(f'{ODIR}/filtered_vcf/{{tum}}_vault_plus_SR_filtered_novaf.vcf.gz'),
        v3=temp(f'{ODIR}/filtered_vcf/{{tum}}_msec_all_filtered_novaf.vcf.gz')
    threads: 1
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    conda:
        "envs/bcftools.yaml"
    log:
        f"{ODIR}/logs/18-msec_filter_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&
        bcftools index {input.v} >> {log} 2>&1 &&

        bcftools view --write-index -i '(
            INFO/filter_7_mutation_at_homopolymer!="TRUE" &&
            INFO/msec_filter_123!="Artifact suspicious" &&
            INFO/filter_4_highly_homologous_region!="TRUE"
          ) || (
            INFO/filter_7_mutation_at_homopolymer!="TRUE" &&
            INFO/msec_filter_123!="Artifact suspicious" &&
            INFO/filter_4_highly_homologous_region=="TRUE" &&
            FMT/DP[1] < 100 &&
            (INFO/CSQ ~ "COSM")
          ) || (
            INFO/msec_filter_123=="Artifact suspicious" &&
            strlen(ALT) > strlen(REF) &&
            (FMT/AD[1:1] - INFO/msec_alt_AD) > 10
          )' {input.v} -Oz -o {output.v1} >> {log} 2>&1 &&

        bcftools view --write-index -i '(
            INFO/filter_7_mutation_at_homopolymer!="TRUE" &&
            INFO/msec_filter_123!="Artifact suspicious" &&
            INFO/filter_4_highly_homologous_region!="TRUE" &&
            INFO/filter_6_simple_repeat!="TRUE"
          ) || (
            INFO/filter_7_mutation_at_homopolymer!="TRUE" &&
            INFO/msec_filter_123!="Artifact suspicious" &&
            INFO/filter_4_highly_homologous_region=="TRUE" &&
            INFO/filter_6_simple_repeat!="TRUE" &&
            FMT/DP[1] < 100 &&
            (INFO/CSQ ~ "COSM")
          ) || (
            INFO/msec_filter_123=="Artifact suspicious" &&
            strlen(ALT) > strlen(REF) &&
            (FMT/AD[1:1] - INFO/msec_alt_AD) > 10
          )' {input.v} -Oz -o {output.v2} >> {log} 2>&1 &&

        bcftools view --write-index -i 'INFO/msec_filter_all!="Artifact suspicious"' {input.v} -Oz -o {output.v3} >> {log} 2>&1
        """

 #  Add VAF tags to the VCF files. 
 # -----------------------------------------------------
rule fill_tags_VAF:
    input:
        f'{ODIR}/filtered_vcf/{{tum}}_vault_filtered_novaf.vcf.gz.csi',
        f'{ODIR}/filtered_vcf/{{tum}}_vault_plus_SR_filtered_novaf.vcf.gz.csi',
        f'{ODIR}/filtered_vcf/{{tum}}_msec_all_filtered_novaf.vcf.gz.csi',
        v1=f'{ODIR}/filtered_vcf/{{tum}}_vault_filtered_novaf.vcf.gz',
        v2=f'{ODIR}/filtered_vcf/{{tum}}_vault_plus_SR_filtered_novaf.vcf.gz',
        v3=f'{ODIR}/filtered_vcf/{{tum}}_msec_all_filtered_novaf.vcf.gz'
    output:
        f'{ODIR}/filtered_vcf/1-{{tum}}_vault_filtered.vcf.gz.csi',
        f'{ODIR}/filtered_vcf/1-{{tum}}_vault_plus_SR_filtered.vcf.gz.csi',
        f'{ODIR}/filtered_vcf/1-{{tum}}_msec_all_filtered.vcf.gz.csi',
        v1=f'{ODIR}/filtered_vcf/1-{{tum}}_vault_filtered.vcf.gz',
        v2=f'{ODIR}/filtered_vcf/1-{{tum}}_vault_plus_SR_filtered.vcf.gz',
        v3=f'{ODIR}/filtered_vcf/1-{{tum}}_msec_all_filtered.vcf.gz'
    threads: 1      
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1  
    conda:
        "envs/bcftools.yaml"
    log:
        f"{ODIR}/logs/19-fill_tags_VAF_{{tum}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&

        bcftools +fill-tags {input.v1} --threads {threads} -Oz -o {output.v1} -- -t FORMAT/VAF >> {log} 2>&1 &&
        bcftools index --force --threads {threads} {output.v1} >> {log} 2>&1 &&
        bcftools +fill-tags {input.v2} --threads {threads} -Oz -o {output.v2} -- -t FORMAT/VAF >> {log} 2>&1 &&
        bcftools index --force --threads {threads} {output.v2} >> {log} 2>&1 &&
        bcftools +fill-tags {input.v3} --threads {threads} -Oz -o {output.v3} -- -t FORMAT/VAF >> {log} 2>&1 &&
        bcftools index --force --threads {threads} {output.v3} >> {log} 2>&1
        """
        
# Filter based on VAF
# -----------------------------------------------------        
rule VAF_filter:
    input:
        f'{ODIR}/filtered_vcf/1-{{tum}}_vault_filtered.vcf.gz.csi',
        f'{ODIR}/filtered_vcf/1-{{tum}}_vault_plus_SR_filtered.vcf.gz.csi',
        f'{ODIR}/filtered_vcf/1-{{tum}}_msec_all_filtered.vcf.gz.csi',
        v1=f'{ODIR}/filtered_vcf/1-{{tum}}_vault_filtered.vcf.gz',
        v2=f'{ODIR}/filtered_vcf/1-{{tum}}_vault_plus_SR_filtered.vcf.gz',
        v3=f'{ODIR}/filtered_vcf/1-{{tum}}_msec_all_filtered.vcf.gz'
    output:
        f'{ODIR}/filtered_vcf/2-{{tum}}_vault_filtered_VAF_{{VAF_threshold}}_filtered.vcf.gz.csi',
        f'{ODIR}/filtered_vcf/2-{{tum}}_vault_plus_SR_filtered_VAF_{{VAF_threshold}}_filtered.vcf.gz.csi',
        f'{ODIR}/filtered_vcf/2-{{tum}}_msec_all_filtered_VAF_{{VAF_threshold}}_filtered.vcf.gz.csi',
        v1=f'{ODIR}/filtered_vcf/2-{{tum}}_vault_filtered_VAF_{{VAF_threshold}}_filtered.vcf.gz',
        v2=f'{ODIR}/filtered_vcf/2-{{tum}}_vault_plus_SR_filtered_VAF_{{VAF_threshold}}_filtered.vcf.gz',
        v3=f'{ODIR}/filtered_vcf/2-{{tum}}_msec_all_filtered_VAF_{{VAF_threshold}}_filtered.vcf.gz'
    threads: 1      
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    conda:
        "envs/bcftools.yaml"
    log:
        f"{ODIR}/logs/20-VAF_filter_{{tum}}_{{VAF_threshold}}.log"
    shell:
        """
        echo "----------------------------------------------" >> {log} 2>&1 &&
        echo "----------------------------------------------" >> {log} 2>&1 &&
        date >> {log} 2>&1 &&
        
        bcftools view --write-index --include 'VAF>{wildcards.VAF_threshold}' {input.v1} -Oz -o {output.v1} >> {log} 2>&1 &&
        bcftools view --write-index --include 'VAF>{wildcards.VAF_threshold}' {input.v2} -Oz -o {output.v2} >> {log} 2>&1 &&
        bcftools view --write-index --include 'VAF>{wildcards.VAF_threshold}' {input.v3} -Oz -o {output.v3} >> {log} 2>&1
        """
    
rule ffpe_signature:
    input:
        unfiltered_vcf=expand(f"{ODIR}/temp/1-reordered_{{tum}}.vcf.gz", tum=samples["tumour_name"]),
        qual_filtered_vcf=expand(f"{ODIR}/PON/3-filtered_{{tum}}.vcf.gz", tum=samples["tumour_name"]),
        vault_filtered_vcf=expand(f"{ODIR}/filtered_vcf/1-{{tum}}_vault_filtered.vcf.gz", tum=samples["tumour_name"]),
        vault_plus_SR_filtered_vcf=expand(f"{ODIR}/filtered_vcf/1-{{tum}}_vault_plus_SR_filtered.vcf.gz", tum=samples["tumour_name"]),
        msec_all_filtered_vcf=expand(f"{ODIR}/filtered_vcf/1-{{tum}}_msec_all_filtered.vcf.gz", tum=samples["tumour_name"]),
        VAF_filtered_vault_vcf=expand(f"{ODIR}/filtered_vcf/2-{{tum}}_vault_filtered_VAF_{{VAF_threshold}}_filtered.vcf.gz", tum=samples["tumour_name"], VAF_threshold=VAF),
        VAF_filtered_vault_plus_SR_vcf=expand(f"{ODIR}/filtered_vcf/2-{{tum}}_vault_plus_SR_filtered_VAF_{{VAF_threshold}}_filtered.vcf.gz", tum=samples["tumour_name"],VAF_threshold=VAF),
        VAF_filtered_msec_all_vcf=expand(f"{ODIR}/filtered_vcf/2-{{tum}}_msec_all_filtered_VAF_{{VAF_threshold}}_filtered.vcf.gz", tum=samples["tumour_name"], VAF_threshold=VAF)
    output:
        repaired_table=f"{ODIR}/ffpe_sig/cosine_similarity_repaired_ffpe_sig.tsv",
        unrepaired_table=f"{ODIR}/ffpe_sig/cosine_similarity_unrepaired_ffpe_sig.tsv",
        plot1=f"{ODIR}/ffpe_sig/cosine_similarity_plot_repaired.pdf",
        plot2=f"{ODIR}/ffpe_sig/cosine_similarity_plot_unrepaired.pdf"
    threads: 1      
    resources:
        mem_mb=4000,
        slurm_cpus_per_task=1
    params:
        ref_genome=str(config["ref_genome_version"]).lower(),
        sample_names=samples["tumour_name"].to_list()
    conda:
        "envs/ffpe_sig.yaml"
    log:
        f"{ODIR}/logs/21-ffpe_signature.log"
    script:
        "scripts/ffpe_sig.R"
